<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Time Series in the Age of Large Models </title> <meta name="author" content="Time Series in the Age of Large Models "> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon-noun-time-series-995090.svg?8e55fa0ecb4b38bd1f9ab75783d55bbb"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://neurips-time-series-workshop.github.io//"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/call-for-papers/">Call for Papers </a> </li> <li class="nav-item "> <a class="nav-link" href="/organizers/">Organizers </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Time Series in the Age of Large Models</span> </h1> <p class="desc">First Workshop on Time Series in the Age of Large Models at the <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS)</a>, December 2024, Vancouver, Canada.</p> </header> <article> <div class="profile float-right"> </div> <div class="clearfix"> <p>This workshop will delve into aspects of time series prediction and analysis in the age of large models. The key topics of this workshop include, but are not limited to:</p> <h3 id="building-foundation-models-for-time-series">Building Foundation Models for Time Series</h3> <p>Foundation models (FMs) have significantly changed the approach to building machine learning models in areas like natural language processing, where models are trained generically on vast amounts of diverse data (<a href="https://arxiv.org/abs/2005.14165" rel="external nofollow noopener" target="_blank">1</a>, <a href="https://arxiv.org/abs/2108.07258" rel="external nofollow noopener" target="_blank">2</a>), and thus can be adapted to perform a range of tasks, even “zero-shot”. Despite their impressive performance, most deep learning models for time series prediction still operate in the standard regime of training and prediction on a single dataset, on a single task. Foundation models for time series have been explored recently (<a href="https://arxiv.org/abs/2310.08278" rel="external nofollow noopener" target="_blank">7</a>, <a href="https://arxiv.org/abs/2403.07815" rel="external nofollow noopener" target="_blank">8</a>, <a href="https://arxiv.org/abs/2402.02592" rel="external nofollow noopener" target="_blank">9</a>, <a href="https://arxiv.org/abs/2402.03885" rel="external nofollow noopener" target="_blank">10</a>, <a href="https://arxiv.org/abs/2310.10688" rel="external nofollow noopener" target="_blank">11</a>). We seek to understand the progress so far as well as the usefulness of these models compared to traditional time series models (in terms of factors such as performance, cost etc.), challenges in developing such models, outline a list of desiderata we would like out of these models, understanding the various design choices for such models, as well as the set of downstream time-series tasks to evaluate such models. We welcome contributions dealing with the challenges that come with the vast amounts of heterogeneous data used for training such models, and in understanding how these models scale (<a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">21</a>, <a href="https://arxiv.org/abs/2405.13867" rel="external nofollow noopener" target="_blank">22</a>, <a href="https://arxiv.org/abs/2405.15124" rel="external nofollow noopener" target="_blank">23</a>) with the amount and diversity of data, with the different design choices. We further welcome contributions on improving the inference cost of such large models, with faster and better inference schemes. Further, it has been difficult to measure progress in FMs for time series due to the different evaluation benchmarks used in papers (<a href="https://arxiv.org/abs/2310.08278" rel="external nofollow noopener" target="_blank">7</a>, <a href="https://arxiv.org/abs/2403.07815" rel="external nofollow noopener" target="_blank">8</a>, <a href="https://arxiv.org/abs/2402.02592" rel="external nofollow noopener" target="_blank">9</a>, <a href="https://arxiv.org/abs/2402.03885" rel="external nofollow noopener" target="_blank">10</a>, <a href="https://arxiv.org/abs/2310.10688" rel="external nofollow noopener" target="_blank">11</a>). We welcome contributions that explore robust evaluation datasets, metrics and benchmarks for such models focused on various tasks. We further welcome contributions on critiques and failure modes of such foundation models.</p> <h2 id="leveraging-pretrained-models-of-other-modalities-for-time-series">Leveraging Pretrained Models of Other Modalities for Time Series</h2> <p>Pretrained large language models (LLMs) have shown extensive promise when adapted to other modalities (such as vision) with minimal adaptation or fine tuning (<a href="https://arxiv.org/abs/2102.01293" rel="external nofollow noopener" target="_blank">27</a>). Recent studies have shown promise in the adaptation of pretrained LLMs to downstream specialized time series tasks (<a href="https://arxiv.org/abs/2310.07820" rel="external nofollow noopener" target="_blank">3</a>, <a href="https://arxiv.org/abs/2302.11939" rel="external nofollow noopener" target="_blank">4</a>, <a href="https://arxiv.org/abs/2310.01728" rel="external nofollow noopener" target="_blank">12</a>, <a href="https://arxiv.org/abs/2310.04948" rel="external nofollow noopener" target="_blank">13</a>, <a href="https://arxiv.org/abs/2308.08241" rel="external nofollow noopener" target="_blank">17</a>, <a href="https://arxiv.org/abs/2405.15370" rel="external nofollow noopener" target="_blank">20</a>). We first seek to understand how the various design choices in leveraging these models, such as the prompting techniques used, adaptation methods used, fine-tuning methods used, etc can have an impact on the performance of the model on various tasks. Further, we also seek to understand in which scenarios such methods can excel, compared to other approaches, specifically such as when training time series FMs from scratch, in terms of the range of capabilities of the model, accuracy, training time, etc. Finally, while the adaptation of LLMs have been explored, the adaptation of pretrained models of other modalities (such as audio, video, images etc.) has been relatively underexplored (<a href="https://arxiv.org/abs/2106.09296" rel="external nofollow noopener" target="_blank">24</a>, <a href="https://arxiv.org/abs/2303.12799" rel="external nofollow noopener" target="_blank">25</a>). We also welcome contributions that compare the adaptation of pretrained models of several modalities in various time series tasks, and discuss the success and failure models of these models.</p> <h2 id="multimodal-time-series-models">Multimodal Time Series Models</h2> <p>Most time-series models in the literature are restricted to only handle numerical time-series data. However, numerical data often only paints a partial picture of the state of a system of interest. In real-world settings, multiple modalities are often available as input, and time series analysis or prediction tasks could potentially be improved by appropriately taking them into account. In this segment of the workshop, we seek to discuss the challenges involved in building such models, and welcome contributions including, but not limited to, attempting to build multimodal time series models (<a href="https://arxiv.org/abs/2305.16556" rel="external nofollow noopener" target="_blank">15</a>), contributions comparing various approaches to fuse different modalities, datasets where time series modalities are paired with data from other modalities (such as text or images). In a similar vein of building multimodal time series models, we welcome contributions that build text-conditioned forecasting models (<a href="https://arxiv.org/abs/2405.13522" rel="external nofollow noopener" target="_blank">16</a>), where textual cues such as news articles or event-related data can be utilized, in addition to the time series data available in a dataset, to condition a model to produce better predictions. We further invite contributions that explore the ability of such multimodal models to understand or infer semantic (such as causal) information between variables for time series analysis.</p> <h2 id="time-series-evaluation-and-real-world-applications">Time Series Evaluation and Real-World Applications</h2> <p>As time-series models grow in capability and move toward real-world impact across business verticals, evaluating progress becomes critical to ensure it translates to deployment. Recent work has exposed shortcomings in current metrics used for evaluation in time series prediction models (<a href="https://arxiv.org/abs/2203.10716" rel="external nofollow noopener" target="_blank">14</a>), specifically in probabilistic prediction models (<a href="https://arxiv.org/abs/2201.08671" rel="external nofollow noopener" target="_blank">5</a>, <a href="https://arxiv.org/abs/2304.09836" rel="external nofollow noopener" target="_blank">6</a>). We seek contributions that deepen our understanding of the failure models of these metrics and contributions developing new metrics for probabilistic prediction evaluation. We further invite contributions that delve deeper into specific real-world applications of time series predictions (such as retail or transportation): in understanding objectives important for each of these specific domains, in an aim to build better evaluation setups for time series models. Finally, we invite contributions that showcase the potential of large time series models in domains such as financial forecasting (<a href="https://arxiv.org/abs/2306.11025" rel="external nofollow noopener" target="_blank">19</a>), human mobility forecasting (<a href="https://arxiv.org/abs/2209.05479" rel="external nofollow noopener" target="_blank">18</a>), weather forecasting (<a href="https://arxiv.org/abs/2301.10343" rel="external nofollow noopener" target="_blank">26</a>) etc.</p> <h3 id="key-information">Key Information</h3> <ul> <li>Submission link: TBD</li> <li>Submission deadline: Sep 15, 2024 (11:59 PM AoE)</li> <li>Acceptance notification: Oct 14, 2024</li> <li>Camera ready deadline: Nov 25, 2024</li> </ul> <p>Please see the <a href="/call-for-papers/">Call for Papers</a> for more information.</p> <h3 id="invited-speakers">Invited Speakers</h3> <p>The workshop features a diverse group of invited speakers who will deliver keynote talks and participate in a panel discussion:</p> <ol> <li> <strong>Mihaela van der Schaar</strong> - University of Cambridge, The Alan Turing Institute</li> <li> <strong>Qingsong Wen</strong> - Squirrel AI Learning Inc.</li> <li> <strong>Valentina Zantedeschi</strong> - ServiceNow, Laval University</li> <li> <strong>Andrew Wilson</strong> - New York University</li> <li> <strong>Christoph Bergmeir</strong> - University of Granada, Spain</li> <li> <strong>Tomas Pfister</strong> - Google Cloud</li> </ol> <h3 id="contact">Contact</h3> <p>You can reach the organizers of the workshop at <a href="mailto:neurips-time-series-workshop@googlegroups.com">neurips-time-series-workshop@googlegroups.com</a>.</p> </div> <div class="social"> <div class="contact-icons"> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Time Series in the Age of Large Models . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Time series icon by Tom from <a href="https://thenounproject.com/icon/time-series-995090/" rel="external nofollow noopener" target="_blank">Noun Project</a>. Last updated: August 02, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-call-for-papers",title:"Call for Papers",description:"",section:"Navigation",handler:()=>{window.location.href="/call-for-papers/"}},{id:"nav-organizers",title:"Organizers",description:"",section:"Navigation",handler:()=>{window.location.href="/organizers/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>